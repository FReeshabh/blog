{
  
    
        "post0": {
            "title": "My first machine learning hackathon. Finishing #2 on both challenges ",
            "content": "Challenges in this Hackathon . This past weekend I participated in the CodeML hackathon, which was my first machine learning hackathon experience. Given this blog post, is about a machine learning hackathon, I feel that it&#39;s quite apt to write this blog in Jupyter Notebooks. . There were 6 challenges hosted on Kaggle, and they were: . Celestial Body Clustering | Anomaly Detection | Reddit comments classification | Sentiment Analysis | Image Classification | Easy Imagenet Classification (Or as I later found out, it was not really Imagenet) | I tried my hand at Challenge 5, and Challenge 6. And this blog post documents my experience with these challenges. . You don&#39;t need your own GPU or expensive hardware! I run a used $100 Thinkpad that I got off eBay. Google Colab, Kaggle, and Paperspace (there&#39;s probably more I&#39;m failing to list here) provide free or inexpensive GPU instances you can use for training your deep models . Challenge 5 - Image classification challenge . I found out that that this challenge was testing out the CIFAR-10 dataset, which I somehow didn&#39;t realize at the time. Nevertheless, I scored a 0.94550 on the private leaderboard with the categorization accuracy metric. . Using Transfer learning . People who have already been actively taking part in Kaggle competitions, or any other machine learning competitions should see this as a no brainer, however for newbies who often try to train their models from scratch in such compeitions might miss on something that can give them a huge jump in performance(they are also particularly popular within Image recognition tasks). . A very brief guide to transfer learning . I don&#39;t plan to teach you transfer learning in this blog however before I send you running off onto the many different resources to learn transfer learning, I&#39;ll explain it a bit. . This deep learning technique enables developers to harness a neural network used for one task and apply it to another domain -Nvidia&#39;s blog . That&#39;s basically it in a nutshell. Let&#39;s say we have a machine learning model trained to classify images within the domain of vehicles - cars, motorcycles, etc. With a bit of tweaking and a little training of the last few layers (or just one) of the network, we can repurpose the model to fit our own task. . We can view how these various pretrained models perform for certain tasks. A popular benchmark to see how these pretrained models would perform on the ImageNet dataset. Here&#39;s Stanford&#39;s DAWNBench. We can see a lot of these top models for image recognition are ResNets. . ResNet and it&#39;s magicks . ResNet is one of the most popular pre-trained models used for image recognition, and it comes in the sizes of 18 layers, 34 layers, 50 layers, and 101 layers (there&#39;s also a 152 model). The paper for Deep Residual Learning for Image Recognition can be found here. . I don&#39;t want to give the impression that transfer learning is only a valid technique for image recognition, in the past few years we have found it emerge it into other fields of machine learnning too. Here&#39;s a talk by Thomas Wolf on using transfer learning for NLP using Hugging Face . You can learn more about ResNet from fastbook, d2l.ai book, or the multiple other resources you can find on the internet. . I used transfer learning with a Resnet 50 model for this image recognition task. . Learning rate finder is a great tool too. And so are discriminative learning rates . Challenge 6 . I used the same approach for this challenge as I did for Challenge 5, and while it initially gave me an edge over other competitors, I realize in hindsight my step 1 should probably have to try to realize what the dataset was. My score was around 68% categorization accuracy on the task, and 70-71% categorization accuracy with a late submission, while the winning submission had a categorization accuracy of 80%+. . Try half point precision for faster training:to_fp_16(), and to_native_fp_16() . So what happened? . An Adversarial Attack . What is an Adversarial attack? . An adversarial attack is when the dataset is designed to intentionally fool the model. In my model, this wasn&#39;t a possibility I had considered. . Final Thoughts and takeaways . Despite not winning the challenges, but still being one of the top teams. I defintely learned a lot, and here are some of my takeaways from the hackathon. . Inspect the dataset: . Not considering an adversarial attack, or recognizing a popular dataset was a mistake on my end. So inspecting the data thouroughly is quite important. . | Consider using transfer learning: . Transfer learning is usually a way to get state of the art results while giving results faster than training a model from scratch. . | Data Visualization and plot confusions: . Check what the model usually messes up on, any data visualizations to aid your understanding of your model&#39;s results will be helpful - Confusion Matrix, most confused list, anything else. . | Revise your model: . After constructing a baseline model. Revise your model! . Try different paramaters. KFold validation. Try a deeper model like ResNet101 (as a last resort). . |",
            "url": "https://freeshabh.github.io/blog/notebook/hackathon/machine-learning/2020/11/23/First-ML-Hackathon-Experience-CodeML-Finishing-second.html",
            "relUrl": "/notebook/hackathon/machine-learning/2020/11/23/First-ML-Hackathon-Experience-CodeML-Finishing-second.html",
            "date": " • Nov 23, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Not just Git Workhsop - EWoCS",
            "content": "Not just git workshop . youtube link: https://youtu.be/76o9TxqnMRg .",
            "url": "https://freeshabh.github.io/blog/workshop/2020/10/03/WORKSHOP-Not-just-a-git-workshop.html",
            "relUrl": "/workshop/2020/10/03/WORKSHOP-Not-just-a-git-workshop.html",
            "date": " • Oct 3, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Virtual Reality Project using Aframe (Covid Human scale experience)",
            "content": "My first introduction to virtual reality . This project was my first experience with virtual reality development. This project is made to be run in a browser and can be viewed by clicking on this link. . This project was made for my CS 4331-5331 class, and more information about this project can be found on the project’s README.md page here. The README file documents all the models, animations, and code snippets used. The next project for this class will use the Unity Game Engine, which is a more topical tool than Aframe for virtual reality development. . This project is licensed under the MIT license, so feel free to use it any way you want :) .",
            "url": "https://freeshabh.github.io/blog/project/2020/10/03/PROJECT-Intro-to-virtual-reality-project.html",
            "relUrl": "/project/2020/10/03/PROJECT-Intro-to-virtual-reality-project.html",
            "date": " • Oct 3, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Archived Posts",
            "content": "Archived Posts of the past . These are not all of the old posts, however most of them are here (Sites might be somewhat broken): . Standup Comedy Experience After 4-5 Months . Link to it: right here . Panda3D Proposals . Link to the SoLoud proposal: right here . | Link to the Native Video proposal: right here . | The illusion series . Link to Illusion and Reality of Bloatware: A meme saga: right here . | Link to Illusion of Choice Linux: right here . | Linear Regression . Link to the notebook: here . Another old blog =&gt; HERE . Ciao? .",
            "url": "https://freeshabh.github.io/blog/markdown/2020/09/09/The-archived-posts.html",
            "relUrl": "/markdown/2020/09/09/The-archived-posts.html",
            "date": " • Sep 9, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Hello! I’m Rishabh. I’m a rising junior at Texas Tech University. I study Computer Science and currently I’m the acting technical lead for EWoCS (Extraordinary Women of Computer Science), so you can find me hosting one of those workshops! I’m also a student researcher under Dr. Amanda Brown for Fall 2020 working on metatranscriptome analysis. And was the marketing lead for HackWesTX 2020 (largest Hackathon in West Texas!). And through the hackathon, I managed to find myself an intern at Group Nire for the Fall 2020 session. . You might also catch me around the town doing a standup comedy routine. . If you want to find me, call on to Cthullu. If Cthullu doesn’t answer, an email is acceptable too rishabhtewari1@gmail.com .",
          "url": "https://freeshabh.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://freeshabh.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}